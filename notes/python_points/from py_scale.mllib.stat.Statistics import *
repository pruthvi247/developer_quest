from py_scale.mllib.stat.Statistics import *

input_dict= {}
input_dict['livy_host'] = 'http://192.168.10.75:8999'
input_dict['sql_host'] = '192.168.2.37'
input_dict['redis_host'] = '192.168.10.75'
input_dict['user'] = 'dsuser_training'
input_dict['passwd'] = 'Noodle1511'
input_dict['db_name'] = 'Ds_training'
input_dict['port'] = '1433'
input_dict['db_type'] = 'sqlserver'
input_dict['redis_port'] = '6379'

query = '''(SELECT [0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15] FROM Ds_training.pred_mnt.cluster_prototype5)t'''



#stats = Statistics(input_dict)

stats = SparkSession(input_dict)

stats.corr(query,input_dict)


rr = get_result("corr", input_dict, "206_0")

###############

schema ='StructType([StructField("cluster", ArrayType(StringType()))])'


udf_code = textwrap.dedent("""@pandas_udf(schema, functionType=PandasUDFType.GROUPED_MAP)\ndef motif_udf(df):\tprint("new line")""")


stats.spark_udf(query,input_dict,schema,udf_code)

