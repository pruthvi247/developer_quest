> Execute the test function with “quiet” reporting mode: pytest -q test_sysexit.py
		
> pytest will run all files of the form test_*.py or *_test.py in the current directory and its subdirectories.

> if you invoke pytest with --ignore=tests/foobar/test_foobar_03.py --ignore=tests/hello/, you will see that pytest only collects test-modules, which do not match the patterns specified

> The --ignore-glob option allows to ignore test file paths based on Unix shell-style wildcards. If you want to exclude test-modules that end with _01.py, execute pytest with --ignore-glob='*_01.py'.

> Tests can individually be deselected during collection by passing the --deselect=item option. For example, say tests/foobar/test_foobar_01.py contains test_a and test_b. You can run all of the tests within tests/ except for tests/foobar/test_foobar_01.py::test_a by invoking pytest with --deselect tests/foobar/test_foobar_01.py::test_a. pytest allows multiple --deselect options.

> It is possible to add your own detailed explanations by implementing the pytest_assertrepr_compare hook

Running pytest can result in six different exit codes:

Exit code 0:	All tests were collected and passed successfully
Exit code 1:	Tests were collected and run but some of the tests failed
Exit code 2:	Test execution was interrupted by the user
Exit code 3:	Internal error happened while executing tests
Exit code 4:	pytest command line usage error
Exit code 5:	No tests were collected

> Run tests by keyword expressions

pytest -k "MyClass and not method"

This will run tests which contain names that match the given string expression, which can include Python operators that use filenames, class names and function names as variables. The example above will run TestMyClass.test_something but not TestMyClass.test_method_simple.
 
> To run a specific test within a module:

pytest test_mod.py::test_func
Another example specifying a test method in the command line:

pytest test_mod.py::TestClass::test_method

> Run tests by marker expressions : pytest -m slow

>
pytest --showlocals # show local variables in tracebacks
pytest -l           # show local variables (shortcut)

pytest --tb=auto    # (default) 'long' tracebacks for the first and last
                     # entry, but 'short' style for the other entries
pytest --tb=long    # exhaustive, informative traceback formatting
pytest --tb=short   # shorter traceback format
pytest --tb=line    # only one line per failure
pytest --tb=native  # Python standard library formatting
pytest --tb=no      # no traceback at all
--full-trace causes very long traces to be printed on error (longer than --tb=long).

> -r flag can be used to display a “short test summary info” 
> for example to only see failed and skipped tests, you can execute: pytest -rfs
> Profiling test execution duration
To get a list of the slowest 10 test durations: pytest --durations=10

Creating resultlog format files: 
-------------------------------
> pytest --resultlog=path
> pytest --pastebin=failed,pytest --pastebin=all

pytest.mark:
-----------
> By using the pytest.mark helper you can easily set metadata on your test functions
> @pytest.mark.skip(reason="no way of currently testing this")
> @pytest.mark.skipif(sys.version_info < (3, 6), reason="requires python3.6 or higher")

XFail: mark test functions as expected to fail
> @pytest.mark.xfail
def test_function():
    ...
Note that no other code is executed after pytest.xfail

@pytest.mark.parametrize: parametrizing test functions :

> @pytest.mark.dependency(depends=['test_copy_files']) - runs only if "test_copy_files" test passes

To read args passed in command line:

@pytest.fixture()
def hdfsPort(pytestconfig):

    return pytestconfig.getoption("hdfsPort")


Note : there should be a conftes.py file to read and parse properties

conftest.py

def pytest_addoption(parser):
	parser.addoption("--hdfsPort", action="store", default=8020)


command to run tests : pytest -q -s -x --hdfsPort=<hdfs_port>





